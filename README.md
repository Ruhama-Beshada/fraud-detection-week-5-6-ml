ğŸ›¡ï¸ Fraud Detection with Explainable Machine Learning
A production-oriented, end-to-end fraud detection system using machine learning, class-imbalance handling, and explainable AI (SHAP). This project emphasizes robust modeling, interpretability, and reproducibility through modular code design and professional Git workflows.

ğŸ“Œ Project Overview
Online transaction fraud is rare, evolving, and costly. This project builds and evaluates machine learning models to detect fraudulent transactions while ensuring:

Explicit handling of extreme class imbalance
Transparent, interpretable predictions using SHAP
Modular, reproducible code organization
Clear separation of data, features, models, and explanations
Two real-world datasets are used:

E-commerce fraud transactions (Fraud_Data.csv)
Credit card transactions (creditcard.csv)
ğŸ§  Key Contributions
âœ” Feature engineering grounded in behavioral fraud signals âœ” Explicit SMOTE-based resampling applied correctly to training data âœ” Comparative modeling with Logistic Regression & Random Forest âœ” Global + local explainability with SHAP summary and force plots âœ” Professional Git workflow (branches + PRs) âœ” Fully reproducible environment and modular pipeline

ğŸ—‚ï¸ Repository Structure
fraud-detection/
â”‚
â”œâ”€â”€ data/                         # (Gitignored)
â”‚   â”œâ”€â”€ raw/                      # Original datasets
â”‚   â””â”€â”€ processed/                # Cleaned & feature-engineered data
â”‚
â”œâ”€â”€ notebooks/                    # Analysis & experimentation
â”‚   â”œâ”€â”€ eda_fraud_data.ipynb
â”‚   â”œâ”€â”€ eda_creditcard.ipynb
â”‚   â”œâ”€â”€ feature_engineering.ipynb
â”‚   â”œâ”€â”€ modeling.ipynb
â”‚   â””â”€â”€ shap_explainability.ipynb
â”‚
â”œâ”€â”€ src/                          # Modular pipeline scripts
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ resampling.py             # Explicit imbalance handling
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â””â”€â”€ explain_model.py
â”‚
â”œâ”€â”€ models/                       # Saved trained models
â”œâ”€â”€ reports/                      # PDF / blog-style report
â”œâ”€â”€ tests/                        # Unit tests
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
âš™ï¸ Environment Setup
git clone https://github.com/your-username/fraud-detection.git
cd fraud-detection
pip install -r requirements.txt
Python Version: 3.9+ All dependencies are explicitly pinned for reproducibility.

ğŸ§¹ Data Preprocessing
Removed duplicates and validated data integrity
Corrected data types (timestamps, numeric, categorical)
Converted IP addresses to integers for geolocation mapping
Merged transactions with IpAddress_to_Country.csv using range-based joins
ğŸ“Œ All preprocessing logic is implemented in:

src/data_preprocessing.py
ğŸ§ª Feature Engineering
Behavior-driven features were created to capture fraud patterns:

Feature	Purpose
time_since_signup	Detect rapid fraud attempts
hour_of_day	Identify abnormal transaction timing
day_of_week	Capture weekly patterns
transactions_per_user	Velocity-based fraud detection
IP range features	Geographic risk estimation
Categorical variables are one-hot encoded, and numerical features are standardized.

âš–ï¸ Class Imbalance Handling (Explicitly Demonstrated)
Fraud cases represent <1% of transactions, requiring careful handling.

âœ” SMOTE is applied only to training data âœ” Test data remains untouched to preserve real-world distribution âœ” Pre- and post-resampling class distributions are visualized and documented

Implementation:

src/resampling.py
ğŸ¤– Modeling & Evaluation
Two models were trained and compared:

Model	Precision	Recall	F1-score	PR-AUC
Logistic Regression	Baseline	Moderate	Moderate	Low
Random Forest	High	High	Best	Best
ğŸ“Œ Evaluation focuses on Recall, F1-score, and PR-AUC, not accuracy.

ğŸ” Explainability with SHAP (Fully Demonstrated)
Explainability is treated as a core requirement, not an add-on.

Global Explainability
SHAP summary plots identify dominant fraud drivers
Results align with domain intuition (IP risk, timing, velocity)
Local Explainability
SHAP force plots for individual transactions

True Positive (correct fraud detection)
False Negative (missed fraud)
These visualizations clearly show why the model made each decision.

ğŸ“Œ Implemented in:

src/explain_model.py
ğŸ“ˆ Key Fraud Drivers Identified
time_since_signup
ip_address and IP range bounds
hour_of_day
transactions_per_user
purchase_value
These insights directly inform business rules and monitoring strategies.

ğŸ’¼ Business Recommendations
Flag transactions occurring minutes after signup
Apply risk scoring to high-risk IP ranges
Increase scrutiny during off-hour transactions
Combine ML predictions with rule-based alerts
ğŸ” Git & Development Workflow
This repository follows professional Git practices:

Feature development on dedicated branches
Pull Requests (PRs) for merging changes
Modular scripts instead of monolithic notebooks
Clear separation of experimentation and production logic
ğŸ“Œ Limitations & Future Improvements
Incorporate anomaly detection for rare fraud patterns
Add real-time scoring pipeline
Implement drift detection and retraining strategy
Expand ensemble modeling
ğŸ“„ Final Report
A full PDF / blog-style report is available in:

reports/final_report.pdf
It includes:

Visual EDA evidence
Model performance comparison
SHAP plots with interpretation
Business impact discussion
ğŸ† Why This Project Is Strong
âœ” Explicit class imbalance handling âœ” Fully demonstrated SHAP explainability âœ” Modular, production-oriented code âœ” Reproducible environment âœ” Clear academic and business value
